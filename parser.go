package hdl

import (
	"fmt"
	"io/ioutil"
	"strconv"
	"strings"
	"unicode"
	"unicode/utf8"
)

// chipClass contains all information needed to instantiate a chip.
type chipClass struct {
	// comment, if any
	comment string
	// sets of input, output and internal buses
	// sets are maps from name to size
	in, out, internal map[string]int
	// set of parts
	// set is a map from an id to the part's name
	parts map[int]string
	// connections
	connections []chipConnection
	// clocked pins (input or output)
	clocked map[string]int
}

// newChipClass returns a pointer to chipClass with non nil maps.
func newChipClass() *chipClass {
	return &chipClass{
		in:       make(map[string]int),
		out:      make(map[string]int),
		internal: make(map[string]int),
		clocked:  make(map[string]int),
		parts:    make(map[int]string),
	}
}

// chipConnection is a connection in a chipClass.
// It connects a chip's pin (in, out, internal)
// to a part's pin (impossible to know if it's an in or out pin here).
type chipConnection struct {
	// part side
	partID     int    // id of the part (see chipClass.parts)
	partBus    string // name of the part's bus
	partPinPos int    // position of the pin in the part's bus
	// chip side
	bus    string // name of the chip's bus
	pinPos int    // position of the pin in the bus
}

// parser stores information about the current state of the parsing state machine.
type parser struct {
	// 'input' of the parser
	lex *lexer

	// output of the parser
	generator *generator

	// state of the parser
	state       stateParse // next state
	currentFile string
	currentChip *chipClass

	// list of files to parse
	// This grows as new dependencies are found
	// A file should appear only once
	files []string
}

// stateParse is a state of the parse state machine
type stateParse func(*parser) stateParse

// generator contains all chip classes required to build the platform
// as well as dependencies.
// It also contains a report with all warnings and errors
// generated by the parser.
type generator struct {
	chips    map[string]*chipClass
	deps     map[string][]string
	errors   []error
	warnings []string
}

// newGenerator returns a pointer to generator with non nil maps.
func newGenerator() *generator {
	return &generator{
		chips: make(map[string]*chipClass),
		deps:  make(map[string][]string),
	}
}

// unexpectedToken appends an 'unexpected token' error to the generator.
func (g *generator) unexpectedToken(t token) {
	g.errors = append(
		g.errors,
		fmt.Errorf("%v l.%v: parser: unexpected token %s", t.file, t.line, t),
	)
}

// lexError appends an error to the generator when the parser receives a lexer error.
func (g *generator) lexError(t token) {
	g.errors = append(
		g.errors,
		fmt.Errorf("%v l.%v: lexer: %v", t.file, t.line, t.val),
	)
}

// errorf appends an error to the generator.
// The given message is prefixed by the file name.
func (g *generator) errorf(file, format string, args ...interface{}) {
	format = file + ": " + format
	g.errors = append(
		g.errors,
		fmt.Errorf(format, args...),
	)
}

// errort appends an error to the generator.
// Since a token is provided, the file and line number are reported (prefix the given message).
func (g *generator) errort(t token, format string, args ...interface{}) {
	format = "%v l.%v" + ": " + format
	fullArgs := []interface{}{t.file, t.line}
	fullArgs = append(fullArgs, args...)
	g.errors = append(
		g.errors,
		fmt.Errorf(format, fullArgs...),
	)
}

// warningf appends a warning to the generator.
func (g *generator) warningf(file, format string, args ...interface{}) {
	format = file + ": " + format
	g.warnings = append(
		g.warnings,
		fmt.Sprintf(format, args...),
	)
}

var (
	// builtinChips is the set of builtin chips.
	// A builtin chip has no chipClass.
	builtinChips = map[string]interface{}{
		"Nand": nil,
		"DFF":  nil,
	}
)

// run runs the parse state machine.
func (p *parser) run() {
	for p.state = parseChip; p.state != nil; {
		p.state = p.state(p)
	}
	// drain the lexer in case there are tokens left
	// this works even if lexer's token channel is closed
	p.lex.drain()
}

// parse parses the given file and its dependencies.
// Dependencies are automatically inferred.
func (p *parser) parse(file string) {
	// prepare generator
	p.generator = newGenerator()

	// init: add given file to the list
	p.files = append(p.files, file)

	// loop through files to build the platform
	// The list of files grows as we find dependencies
	for i := 0; i < len(p.files); i++ {
		// validate filename
		splitFilename := strings.Split(p.files[i], ".")
		if len(splitFilename) != 2 || splitFilename[1] != "hdl" {
			p.generator.errorf(p.files[i], "invalid filename: expecting Xxx.hdl")
			return
		}
		// get file content
		content, err := ioutil.ReadFile(p.files[i])
		if err != nil {
			// store error and stop immediately
			p.generator.errorf(p.files[i], err.Error())
			return
		}

		// prepare parser:
		p.currentFile = p.files[i]
		p.currentChip = newChipClass()
		p.lex = lex(p.currentFile, string(content))
		// run the parse state machine
		p.run()
	}
	return
}

// checkToken checks that the token is an expected token
// and if it is not an error token (an error token cannot be expected).
// If everything is fine 'true' is returned
// and it is guaranteed that the given token belonds to list of valid tokens.
// Otherwise it returns false and stores an error in the generator.
func (p *parser) checkToken(t token, validTokens ...tokenType) bool {
	// Is this an error?
	if t.typ == tokenError {
		p.generator.lexError(t)
		return false
	}
	// Is this an expected token?
	var valid bool
	for _, validToken := range validTokens {
		if t.typ == validToken {
			valid = true
			break
		}
	}
	// if not valid, add error to the generator
	if !valid {
		p.generator.unexpectedToken(t)
	}

	return valid
}

// nextToken returns the next token from the lexer
func (p *parser) nextToken() (t token) {
	t = p.lex.nextToken()
	return
}

// ignoreComments returns the next non comment token.
func (p *parser) ignoreComments() token {
	t := p.nextToken()
	for t.typ == tokenCommentAPI {
		t = p.nextToken()
	}
	return t
}

// parseComment reads API comments
// and remembers the last
// until the chip declaration starts.
func parseComment(p *parser) stateParse {
	// read next token
	tok := p.nextToken()
	if !p.checkToken(tok, tokenCommentAPI, tokenDecl) {
		return nil // fatal error for the moment: stop here
	}

	// token is valid
	switch tok.typ {

	case tokenCommentAPI:
		// write this comment onto the previous one
		// i.e. keep only the last one
		p.currentChip.comment = tok.val
		// start again
		return parseComment

	case tokenDecl:
		// start chip declaration
		return parseName
	}
	// nothing else can happen
	return nil
}

// parseName reads and validate the chip name.
func parseName(p *parser) stateParse {
	//read token and validate it
	// the CHIP token has already been consumed,
	// so we expect the chip name now (or comments that we ignore)
	tok := p.ignoreComments()
	if !p.checkToken(tok, tokenIdentifier) {
		return nil // fatal error for the moment: stop here
	}

	// token identifier containing the name of the chip
	name := tok.val
	//check name formatting: name starts with an upper case letter
	r1, _ := utf8.DecodeRuneInString(name)
	if !unicode.IsUpper(r1) {
		p.generator.warningf(p.currentFile, "chip name %q should start with an upper case letter", name)
	}
	// check consistency between chip and filename
	filePrefix := strings.Split(p.currentFile, ".")[0] // I know that filename has the correct Xxx.hdl structure
	if filePrefix != name {
		p.generator.errorf(p.currentFile, "inconsistent filename and chip name: %q and %q", filePrefix, name)
		return nil
	}
	// chip name is valid: remember it
	p.generator.chips[name] = p.currentChip

	// consume the implementation left delimiter and comments
	tok = p.ignoreComments()
	if !p.checkToken(tok, tokenLeftDelim) {
		return nil
	}
	// token is valid
	// start parsing the chip implementation
	return parseChip

}

// parseChip parses the content of the chip (in, out, parts, clocked).
func parseChip(p *parser) stateParse {
	tok := p.ignoreComments()
	if !p.checkToken(tok, tokenIN, tokenOUT, tokenPARTS, tokenCLOCKED) {
		return nil // fatal error for the moment: stop here
	}

	// token is valid
	// consume it and go the right state
	switch tok.typ {
	case tokenIN:
		return parseIn
	case tokenOUT:
		return parseOut
	case tokenPARTS:
		return parseParts
	case tokenCLOCKED:
		return parseClocked
	}
	// nothing else can happen
	return nil
}

// OLD CODE: START AGAIN
// parseIn parses an input bus.
// It returns parseIn as long as there is an input bus left.
// When all input buses have been parsed it returns parseChip.
func parseIn(p *parser) stateParse {
	// parse input bus
	switch parseBus(p, p.currentChip.in) {
	case stop:
		// fatal error: stop here
		return nil
	case goOn:
		// there is an input bus left, parse it
		return parseIn
	default:
		// done: all input buses have been parsed
		return parseChip
	}
}

// parseOut parses the output buses of the chip.
func parseOut(p *parser) stateParse {
	// parse output bus
	switch parseBus(p, p.currentChip.out) {
	case stop:
		// fatal error: stop here
		return nil
	case goOn:
		// there is an output bus left, parse it
		return parseOut
	default:
		// done: all input buses have been parsed
		return parseChip
	}

}

func parseClocked(p *parser) stateParse {
	return nil
}

func parseParts(p *parser) stateParse {
	return nil
}

// result of parsing a bus
const (
	done = iota
	goOn
	stop
)

// parseBus parses a bus and writes it to the given map.
// The first (non comment) token it receives must be an identifier.
// It stops when it reads ',', ';' or an unexpected token.
// This last token is consumed.
// It returns
//  - 'done' is all input buses have been parsed,
//  - 'goOn' if there is an input bus left,
//  - 'stop' if a fatal error occured.
func parseBus(p *parser, buses map[string]int) int {
	tok := p.ignoreComments()
	// check token
	if !p.checkToken(tok, tokenIdentifier) {
		return stop // fatal error: stop here
	}

	// read bus

	// we have the pin/bus name
	name := tok.val
	// check that bus has not been declared yet
	if _, present := buses[name]; present {
		p.generator.errort(tok, "bus %q redeclared", name)
		// not a fatal error: continue
	}
	// perform some checks: emit a warning if the first character is upper case
	r1, _ := utf8.DecodeRuneInString(name)
	if unicode.IsUpper(r1) {
		p.generator.warningf(p.currentFile, "pin or bus name %q should start with a lower case letter", name)
	}

	// what is the size of the bus? We need to read next token to know
	size := 1 // default value
	tok = p.ignoreComments()
	if !p.checkToken(tok, tokenLeftIndex, tokenComma, tokenSemiCol) {
		return stop // fatal error for the moment: stop here
	}

	if tok.typ == tokenLeftIndex {
		// this is a bus, not a simple pin: read its size
		tok = p.ignoreComments()
		if !p.checkToken(tok, tokenNumber) {
			return stop // fatal error: stop here
		}
		//ok, I have the size of the bus
		var err error
		size, err = strconv.Atoi(tok.val)
		if err != nil {
			// this should never happen
			p.generator.errorf(p.currentFile, "invalid size format %q", tok.val)
			return stop // error: stop here
		}

		// close bracket
		tok = p.ignoreComments()
		if !p.checkToken(tok, tokenRightIndex) {
			return stop // error: stop here
		}

		// I know the bus name and its size
		p.currentChip.in[name] = size

		// read next token
		tok = p.ignoreComments()
		if !p.checkToken(tok, tokenComma, tokenSemiCol) {
			return stop // error: stop here
		}
	}

	// token is ',' or ';' now
	switch tok.typ {
	case tokenComma:
		// continue reading input buses
		return goOn
	case tokenSemiCol:
		// done reading buses
		return done
	}
	// nothing else should happen
	return stop
}
